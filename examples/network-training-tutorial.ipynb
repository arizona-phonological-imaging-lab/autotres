{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "*Why `HDF5`?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "\n",
    "For most purposes, we are going to want to set our logging level to INFO, since some commands are going to run for a long time, and we would like periodic updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an `HDF5` database\n",
    "\n",
    "The first step is to create a dataset. This process is mostly abstracted away for you using a3.Dataset objects. Your responsibility is to specify how your data is stored and structured. We'll start by specifying some structure. \n",
    "\n",
    "### Keys\n",
    "\n",
    "For my dataset, there are a number of subjects, and for each subject there is a number of ultrasound frames. Importantly, this relationship is heirarchical in that any data that is associated with a subject but not with a frame (for example, an audio recording of the session) is valid for all frames for that subject, whereas information that is associated with a frame number (such as a trace) won't be valid for all subjects. We encode this nesting with the list `['subject','frame']`. If, for example, each subject participated 3 times, we might specify a nesting like `['subject','session','frame']`. These constitute 'keys' in the database sense: a combination of a subject ID, session ID, and frame ID pick out a unique datapoint. The last element will usually be frame, since that is usually the minimal unit of analysis. \n",
    "\n",
    "Note that these names are arbitrary, as long a you are consistant. Of course using informative names is best practice, since autotres has some sensible defaults that rely on certain keys; for example, the default code for extracting images from video relies on a `'frame'` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['subject','frame']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "Next, we need to be able to tell autotres about the types of files we have, the types of data they represent, and what levels of the key heirarchy each piece of data should be associated with. This will mostly be accomplished with regular expressions. We create a dict of data types. The keys of the dict represent data type names. Note that we will want one type for each type of data we want, not for each type of file we have. Autotres is perfectly happy pulling more than one type of information from a file. \n",
    "\n",
    "These are again arbitrary labels, but autotres can provide some sensible default behaviors for certain labels. Each dict contains information about that type:\n",
    "\n",
    "#### `'conflict'`: How to deal with multiple files of the same type appearing for same combination of identifiers. \n",
    "\n",
    "For example, If I have multiple tracers on my team, then I would expect to have multiple 'trace' files for each combination of 'subject' and 'frame'. In this case, I would like to keep all of the traces for the same image, so that I can do something sensible with it, like interpolate. In this case I will set the value for 'conflict' to 'list'. \n",
    "\n",
    "Similarly, if I have conducted multiple studies with my dataset, one looking at coronals and one looking at fricatives, I would expect to have multiple copies of the images for coronal fricatives. However, unlike the instance with multiple traces, `fricative_frame-00042.png` and `coronal_frame-00042.png` should be identical files. I can use the 'hash' option to specify that I should ignore duplicates as long as they are the same, but should raise an exception if they don't.\n",
    "\n",
    "Finally, there are some situations that I simply expect not to happen. For example, if a single subject is associated with more that one 'audio' file, then perhaps it is most likely that somebdy mislabeled something. In this case, I would not set 'conflict' to anything, and if there is a conflict, autotres will raise an exception automatically\n",
    "\n",
    "#### `'regex'`: How to associate each file with a combination of heirachical levels.\n",
    "\n",
    "This is a regular expression that will match a filename in the dataset. We use the `(?P<label>...)` syntax to capture parts of the filename that are informative. Specifically, we need to be able to infer all the relevent heirarchical information from the file name. This should be a left-substring of the keys list. \n",
    "\n",
    "Note that the regex is matched to the entire pathname, relative to whatever path we give it (see below). Here, we have also used the `(?x)` flag to allow us to break the regex over multiple lines, and to include comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "types = {\n",
    "    'trace': {\n",
    "        'conflict': 'list',\n",
    "        'regex': r\"\"\"(?x)\n",
    "            %(sep)s                 # from (the last) file separater\n",
    "            (?P<subject>\\d\\d[a-c])  # we expect a 'subject' ID of the form: 42a\n",
    "            [^%(sep)s]+             # and a bunch of junk, (but not a file separator)\n",
    "            frame-(?P<frame>\\d+)    # then the literal word frame, followed by a 'frame' number\n",
    "            \\.(?:png|jpg)           # an image file extension\n",
    "            \\.(?P<tracer>\\w+)       # the tracer's initials\n",
    "            \\.traced\\.txt$          # and our trace files end with .txt\n",
    "            \"\"\"%{'sep':os.sep},\n",
    "        },\n",
    "    'image': {\n",
    "        'conflict': 'hash',\n",
    "        'regex': r\"\"\"(?x)\n",
    "            %(sep)s                 # like trace files\n",
    "            (?P<subject>\\d\\d[a-c])  # here's our 'subject'\n",
    "            [^%(sep)s]+             # bunch of junk\n",
    "            frame-(?P<frame>\\d+)    # frame number\n",
    "            \\.(?P<ext>png|jpg)$     # file extension\n",
    "            \"\"\"%{'sep':os.sep},\n",
    "        },\n",
    "    'name': {\n",
    "            'conflict':'list',\n",
    "        'regex': r\"\"\"(?x)                   # this will give us the file name of the image\n",
    "            (?P<subject>\\d\\d[a-c])_[-0-9]+  # 'subject' id\n",
    "            .*                              # \n",
    "            %(sep)s                         # (last) file separator\n",
    "            (?P<fname> [^%(sep)s]+          # we want the whole file name\n",
    "            frame-(?P<frame>\\d+)            # including the 'frame' number, with a nested (?P<>) \n",
    "            \\.(?:png|jpg))$                 # up to the end of the filename\n",
    "            \"\"\"%{'sep':os.sep},\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset\n",
    "\n",
    "We will now set up our dataset. The `roi`, `n_points`, and `scale` kwargs will be passed down to the default data extraction callbacks (see a3/dataset.py documentation). Custom callbacks can be provided by putting a callable in the ds.callbacks dict. These should return a numpy array of type `float32`. \n",
    "\n",
    "If you don't have CUDA properly installed, importing a3 will throw some errors about nvcc (nvidia cuda compiler) not being found. This is fine so long as you are fine with only using the CPU (instead of the GPU) to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import a3\n",
    "\n",
    "ds = a3.Dataset('SG.hdf5',roi=(140.,320.,250.,580.),n_points=32,scale=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory containing our data is `./SG/` using our types and our key heirarchy. You can scan multiple directories if you need to, possibly with different type definitions, but watch out for file conflicts! Your heirarchy should be the same accross calls to `scan_directory`. For large datasets may take a while to complete, since it is doing a full walk of the file heirarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.scan_directory('./SG/',types,keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can inspect what data sources you have by looking at the `ds.sources` dict. Watch out, this dict can get very large, so don't try printing the actual contents to `stdout` unless you've got a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.sources.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your data sources figured out, you can extract that data with ds.read_sources(). The arg here is a set-like object with all of the data types you need. This will take a while, since it is opening and processing a lot of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.read_sources(['trace','image','name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a network\n",
    "\n",
    "The rest is easy. Construct an `Autotracer` from your new dataset. Specifying `None` for the validation set sets aside part of your training data as validation data (no guarantees about randomness). Make sure you use the same ROI as above, or at least the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a3.Autotracer('SG.hdf5',None,roi=(140.,320.,250.,580.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To train on your dataset, simply call the `train()` method. In reality, training will require thousands of epochs (runs through the entire dataset), but for time we will just train a couple times. Minibatch size can be controlled with the `minibatch` kwarg, which defaults to `512`. If your logging level is set to INFO you will see the training loss and validation loss at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you save your weights! Note that the resulting file doesn't contain any information about the layout of the NNet -- that's still in the works. To change layouts, change the code in `a3.Autotrace.__init_layers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.save('example.a3.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a network\n",
    "\n",
    "Get the traces for your dataset! This will create a file named `SG_test.json` that can be used with the APIL web tracer. The remaining positional arguments are the filenames for the images, the tracer ID, and subject ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('SG.hdf5','r') as h:\n",
    "    a.trace(h['image'],'SG_test.json',h['name'],'autotrace_test','042')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If youwant to know your loss, you can just train once, with your test dataset as the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b = a3.Autotracer('SG.hdf5','test.hdf5',roi=(140.,320.,250.,580.))\n",
    "# b.train(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
